{"ast":null,"code":"import React, { useRef, useEffect } from 'react';\nimport './App.css';\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport * as tf from \"@tensorflow/tfjs\";\nconst runPoseMesh = async () => {\n  await tf.ready(); // Ensure the TensorFlow.js is ready\n  await tf.setBackend('webgl'); // Set the TensorFlow.js backend\n\n  const net = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {\n    modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING\n  });\n  const detect = async () => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const videoWidth = video.videoWidth;\n      const videoHeight = video.videoHeight;\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n      const poses = await net.estimatePoses(video);\n      console.log(poses);\n\n      // Draw the poses onto the canvas\n      const ctx = canvasRef.current.getContext(\"2d\");\n      ctx.clearRect(0, 0, videoWidth, videoHeight);\n      ctx.drawImage(video, 0, 0, videoWidth, videoHeight);\n      poses.forEach(({\n        keypoints\n      }) => {\n        keypoints.forEach(({\n          x,\n          y,\n          score\n        }) => {\n          if (score > 0.5) {\n            ctx.beginPath();\n            ctx.arc(x, y, 5, 0, 2 * Math.PI);\n            ctx.fillStyle = \"red\";\n            ctx.fill();\n          }\n        });\n      });\n    }\n  };\n  setInterval(detect, 100);\n};","map":{"version":3,"names":["React","useRef","useEffect","poseDetection","tf","runPoseMesh","ready","setBackend","net","createDetector","SupportedModels","MoveNet","modelType","movenet","SINGLEPOSE_LIGHTNING","detect","webcamRef","current","video","readyState","videoWidth","videoHeight","width","height","canvasRef","poses","estimatePoses","console","log","ctx","getContext","clearRect","drawImage","forEach","keypoints","x","y","score","beginPath","arc","Math","PI","fillStyle","fill","setInterval"],"sources":["C:/Users/PC/Desktop/CodingStuff/BuildSpace/pose-js/src/components/PoseMesh.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\r\nimport './App.css';\r\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\n\r\nconst runPoseMesh = async () => {\r\n    await tf.ready(); // Ensure the TensorFlow.js is ready\r\n    await tf.setBackend('webgl'); // Set the TensorFlow.js backend\r\n\r\n    const net = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {\r\n      modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,\r\n    });\r\n\r\n    const detect = async () => {\r\n      if (\r\n        typeof webcamRef.current !== \"undefined\" &&\r\n        webcamRef.current !== null &&\r\n        webcamRef.current.video.readyState === 4\r\n      ) {\r\n        const video = webcamRef.current.video;\r\n        const videoWidth = video.videoWidth;\r\n        const videoHeight = video.videoHeight;\r\n\r\n        webcamRef.current.video.width = videoWidth;\r\n        webcamRef.current.video.height = videoHeight;\r\n\r\n        canvasRef.current.width = videoWidth;\r\n        canvasRef.current.height = videoHeight;\r\n\r\n        const poses = await net.estimatePoses(video);\r\n        console.log(poses);\r\n\r\n        // Draw the poses onto the canvas\r\n        const ctx = canvasRef.current.getContext(\"2d\");\r\n        ctx.clearRect(0, 0, videoWidth, videoHeight);\r\n        ctx.drawImage(video, 0, 0, videoWidth, videoHeight);\r\n\r\n        poses.forEach(({ keypoints }) => {\r\n          keypoints.forEach(({ x, y, score }) => {\r\n            if (score > 0.5) {\r\n              ctx.beginPath();\r\n              ctx.arc(x, y, 5, 0, 2 * Math.PI);\r\n              ctx.fillStyle = \"red\";\r\n              ctx.fill();\r\n            }\r\n          });\r\n        }\r\n      );\r\n      }\r\n    };\r\n\r\n    setInterval(detect, 100);\r\n  };"],"mappings":"AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAChD,OAAO,WAAW;AAClB,OAAO,KAAKC,aAAa,MAAM,mCAAmC;AAClE,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AAEtC,MAAMC,WAAW,GAAG,MAAAA,CAAA,KAAY;EAC5B,MAAMD,EAAE,CAACE,KAAK,CAAC,CAAC,CAAC,CAAC;EAClB,MAAMF,EAAE,CAACG,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC;;EAE9B,MAAMC,GAAG,GAAG,MAAML,aAAa,CAACM,cAAc,CAACN,aAAa,CAACO,eAAe,CAACC,OAAO,EAAE;IACpFC,SAAS,EAAET,aAAa,CAACU,OAAO,CAACD,SAAS,CAACE;EAC7C,CAAC,CAAC;EAEF,MAAMC,MAAM,GAAG,MAAAA,CAAA,KAAY;IACzB,IACE,OAAOC,SAAS,CAACC,OAAO,KAAK,WAAW,IACxCD,SAAS,CAACC,OAAO,KAAK,IAAI,IAC1BD,SAAS,CAACC,OAAO,CAACC,KAAK,CAACC,UAAU,KAAK,CAAC,EACxC;MACA,MAAMD,KAAK,GAAGF,SAAS,CAACC,OAAO,CAACC,KAAK;MACrC,MAAME,UAAU,GAAGF,KAAK,CAACE,UAAU;MACnC,MAAMC,WAAW,GAAGH,KAAK,CAACG,WAAW;MAErCL,SAAS,CAACC,OAAO,CAACC,KAAK,CAACI,KAAK,GAAGF,UAAU;MAC1CJ,SAAS,CAACC,OAAO,CAACC,KAAK,CAACK,MAAM,GAAGF,WAAW;MAE5CG,SAAS,CAACP,OAAO,CAACK,KAAK,GAAGF,UAAU;MACpCI,SAAS,CAACP,OAAO,CAACM,MAAM,GAAGF,WAAW;MAEtC,MAAMI,KAAK,GAAG,MAAMjB,GAAG,CAACkB,aAAa,CAACR,KAAK,CAAC;MAC5CS,OAAO,CAACC,GAAG,CAACH,KAAK,CAAC;;MAElB;MACA,MAAMI,GAAG,GAAGL,SAAS,CAACP,OAAO,CAACa,UAAU,CAAC,IAAI,CAAC;MAC9CD,GAAG,CAACE,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEX,UAAU,EAAEC,WAAW,CAAC;MAC5CQ,GAAG,CAACG,SAAS,CAACd,KAAK,EAAE,CAAC,EAAE,CAAC,EAAEE,UAAU,EAAEC,WAAW,CAAC;MAEnDI,KAAK,CAACQ,OAAO,CAAC,CAAC;QAAEC;MAAU,CAAC,KAAK;QAC/BA,SAAS,CAACD,OAAO,CAAC,CAAC;UAAEE,CAAC;UAAEC,CAAC;UAAEC;QAAM,CAAC,KAAK;UACrC,IAAIA,KAAK,GAAG,GAAG,EAAE;YACfR,GAAG,CAACS,SAAS,CAAC,CAAC;YACfT,GAAG,CAACU,GAAG,CAACJ,CAAC,EAAEC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGI,IAAI,CAACC,EAAE,CAAC;YAChCZ,GAAG,CAACa,SAAS,GAAG,KAAK;YACrBb,GAAG,CAACc,IAAI,CAAC,CAAC;UACZ;QACF,CAAC,CAAC;MACJ,CACF,CAAC;IACD;EACF,CAAC;EAEDC,WAAW,CAAC7B,MAAM,EAAE,GAAG,CAAC;AAC1B,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}